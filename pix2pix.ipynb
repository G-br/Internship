{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library importation\n",
    "import gc\n",
    "import numpy as np\n",
    "from numpy import load\n",
    "from numpy import zeros\n",
    "from numpy import ones\n",
    "from numpy.random import randint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.initializers import RandomNormal\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Conv2DTranspose\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Concatenate\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import LeakyReLU\n",
    "from matplotlib import pyplot as plt\n",
    "from os import listdir\n",
    "from PIL import Image\n",
    "%env SM_FRAMEWORK=tf.keras\n",
    "import segmentation_models as sm\n",
    "from segmentation_models import Unet\n",
    "from segmentation_models import get_preprocessing\n",
    "import tensorflow as tf\n",
    "from tifffile import imread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Defining the functions to create the Pix2Pix network inspired by Jason Brownlee's Pix2Pix Example\n",
    "\"\"\"\n",
    "# define the discriminator model\n",
    "def define_discriminator(image_shape):\n",
    "    # weight initialization\n",
    "    init = RandomNormal(stddev=0.02) #( RandomNormal is a initializer that generates tensors with a normal distribution.)\n",
    "    # source image input\n",
    "    in_src_image = Input(shape=image_shape)\n",
    "    # target image input\n",
    "    in_target_image = Input(shape=image_shape)\n",
    "    # concatenate images channel-wise\n",
    "    merged = Concatenate()([in_src_image, in_target_image])\n",
    "    # C64\n",
    "    d = Conv2D(64, (3,3), strides=(2,2), padding='same', kernel_initializer=init)(merged)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    # C128\n",
    "    d = Conv2D(128, (3,3), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
    "    d = BatchNormalization()(d)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    # C256\n",
    "    d = Conv2D(256, (3,3), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
    "    d = BatchNormalization()(d)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    # C512\n",
    "    d = Conv2D(512, (3,3), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
    "    d = BatchNormalization()(d)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    # second last output layer\n",
    "    d = Conv2D(512, (3,3), padding='same', kernel_initializer=init)(d)\n",
    "    d = BatchNormalization()(d)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    # patch output\n",
    "    d = Conv2D(1, (3,3), padding='same', kernel_initializer=init)(d)\n",
    "    patch_out = Activation('sigmoid')(d)\n",
    "    # define model\n",
    "    model = Model([in_src_image, in_target_image], patch_out)\n",
    "    # compile model\n",
    "    opt = Adam(learning_rate=1e-4, beta_1=0.5)   \n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt, loss_weights=[0.1])\n",
    "    return model\n",
    "\n",
    "# define the standalone generator model\n",
    "def define_generator(image_shape=(256,256,1)):\n",
    "    # define model\n",
    "    sm.set_framework('tf.keras')\n",
    "    sm.framework()\n",
    "    model = Unet(\"efficientnetb0\",encoder_weights=None,activation=\"tanh\", input_shape=(256, 256, 1),classes=1)\n",
    "    return model\n",
    "\n",
    "# define the combined generator and discriminator model, for updating the generator\n",
    "def define_gan(g_model, d_model, image_shape):\n",
    "    # make weights in the discriminator not trainable\n",
    "    for layer in d_model.layers:\n",
    "        if not isinstance(layer, BatchNormalization):\n",
    "            layer.trainable = False\n",
    "    # define the source image\n",
    "    in_src = Input(shape=image_shape)\n",
    "    # connect the source image to the generator input\n",
    "    gen_out = g_model(in_src)\n",
    "    # connect the source input and generator output to the discriminator input\n",
    "    dis_out = d_model([in_src, gen_out])\n",
    "    # src image as input, generated image and classification output\n",
    "    model = Model(in_src, [dis_out, gen_out])\n",
    "    # compile model\n",
    "    opt = Adam(learning_rate=1e-4, beta_1=0.8)\n",
    "    model.compile(loss=['binary_crossentropy', 'mse'], optimizer=opt, loss_weights=[10,100])\n",
    "    return model\n",
    "\n",
    "\n",
    "# select a batch of random samples, returns images and target\n",
    "def generate_real_samples_(dataset, n_samples, patch_shape):\n",
    "    # unpack dataset\n",
    "    trainA, trainB = dataset\n",
    "    # choose random instances\n",
    "    ix = randint(0, trainA.shape[0], n_samples)\n",
    "    print(np.shape(ix))\n",
    "    # retrieve selected images\n",
    "    X1, X2 = trainA[ix], trainB[ix]\n",
    "    # generate 'real' class labels (1)\n",
    "    y = ones((n_samples, patch_shape, patch_shape, 1))\n",
    "    return [X1, X2], y\n",
    "\n",
    "# select a batch of random samples, returns images and target\n",
    "def generate_real_samples(dataset, n_samples, patch_shape,ix):\n",
    "    # unpack dataset\n",
    "    trainA, trainB = dataset\n",
    "    # choose random instances\n",
    "        # done outside of the function\n",
    "    # retrieve selected images\n",
    "    X1, X2 = trainA[ix], trainB[ix]\n",
    "    # generate 'real' class labels (1)\n",
    "    y = ones((n_samples, patch_shape, patch_shape, 1))\n",
    "    return [X1, X2], y\n",
    "\n",
    "# generate a batch of images, returns images and targets\n",
    "def generate_fake_samples(g_model, samples, patch_shape):\n",
    "    # generate fake instance\n",
    "    X = g_model.predict(samples)\n",
    "    # create 'fake' class labels (0)\n",
    "    y = zeros((len(X), patch_shape, patch_shape, 1))\n",
    "    return X, y\n",
    "\n",
    "# train pix2pix models\n",
    "def train(d_model, g_model, gan_model, dataset, n_epochs=10, n_batch=16,save=False):\n",
    "    # determine the output square shape of the discriminator\n",
    "    n_patch = d_model.output_shape[1]\n",
    "    # unpack dataset\n",
    "    trainA, trainB = dataset\n",
    "    # calculate the number of batches per training epoch\n",
    "    bat_per_epo = int(len(trainA) / n_batch)\n",
    "    # calculate the number of training iterations\n",
    "    n_steps = bat_per_epo * n_epochs\n",
    "    print(n_steps)\n",
    "    # manually enumerate epochs\n",
    "    gmin=1000000.0\n",
    "    dmin=1000000.0\n",
    "    tab_ix = np.random.permutation(len(trainA))\n",
    "    tab_ix = np.reshape(tab_ix[:n_batch*(tab_ix.shape[0]//n_batch)],(bat_per_epo,-1))\n",
    "    j=0\n",
    "    for i in range(n_steps):\n",
    "        # select a batch of real samples\n",
    "        if j==tab_ix.shape[0]:\n",
    "            j=0\n",
    "            tab_ix = np.random.permutation(len(trainA))\n",
    "            tab_ix = np.reshape(tab_ix[:n_batch*(tab_ix.shape[0]//n_batch)],(bat_per_epo,-1))\n",
    "        ix=tab_ix[j]\n",
    "        j+=1\n",
    "        [X_realA, X_realB], y_real = generate_real_samples(dataset, n_batch, n_patch, ix)\n",
    "        # generate a batch of fake samples\n",
    "        X_fakeB, y_fake = generate_fake_samples(g_model, X_realA, n_patch)\n",
    "        # update discriminator for real samples\n",
    "        d_loss1 = d_model.train_on_batch([X_realA, X_realB], y_real)\n",
    "        # update discriminator for generated samples\n",
    "        d_loss2 = d_model.train_on_batch([X_realA, X_fakeB], y_fake)\n",
    "        # update the generator\n",
    "        g_loss1, g_loss2, g_loss3 = gan_model.train_on_batch(X_realA, [y_real, X_realB])\n",
    "        # summarize performance\n",
    "        print('>%d, d1[%.3e] d2[%.3e] g[%.3e,%.3e,%.3e]' % (i+1, d_loss1, d_loss2, g_loss1, g_loss2, g_loss3))\n",
    "        # Saving the network every time it become better and when the network already did at least 500 batches.\n",
    "        if g_loss1<gmin:\n",
    "            gmin = g_loss1\n",
    "            if save and i>10:\n",
    "                g_model.save(\"Networks/Pix2Pix_gen__8_low_mse\")\n",
    "                d_model.save(\"Networks/Pix2Pix_det__8_low_mse\")\n",
    "                # displaying the original/prediction/corrected\n",
    "                plt.figure()\n",
    "                plt.imshow(X_realA[0,...,0],cmap=\"gray\")\n",
    "                plt.figure()\n",
    "                plt.imshow(X_fakeB[0,...,0],cmap=\"gray\")\n",
    "                plt.figure()\n",
    "                plt.imshow(X_realB[0,...,0],cmap=\"gray\")\n",
    "                plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importation of data\n",
    "\n",
    "#Original Image\n",
    "path=\"Detectors_sham/\"\n",
    "data=[imread(path+image) for image in [\"stack6.lsm\",\"stack7.lsm\",\"stack8.lsm\"]]\n",
    "data_concat = (np.concatenate((data[0],data[1],data[2]),axis = 0))\n",
    "X = data_concat[:,2]\n",
    "Y = data_concat[:,1]\n",
    "#turning them into tensors \n",
    "X=np.expand_dims(X,axis=3)\n",
    "Y=np.expand_dims(Y,axis=3)\n",
    "x_train,y_train=X,Y\n",
    "print(np.shape(x_train),np.shape(y_train))\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Procedure to cut the image into smaller pieces\n",
    "class Tile:\n",
    "    '''\n",
    "    Usage    : Tile(image,tilesize,overlap,verbose)\n",
    "    image    : Array of shape [height,width,canals]\n",
    "    tilesize : The output will be of shape [tilesize,tilesize,canals]\n",
    "    overlap  : Amount of pixel common between two consecutive tiles\n",
    "    ================================================================\n",
    "    Methods  :\n",
    "    padding(mode=\"reflect\"): Returns a padded image via numpy.pad usage\n",
    "    tilegeneration()       : Returns a list parts of original image(tiles)\n",
    "    tilevis(concat=True)   : Plots the tiles list for the image\n",
    "    detmask()              : Returns the mask of overlapping areas\n",
    "    reconstruct()          : Builds the image back out of the tile list   \n",
    "    '''\n",
    "    \n",
    "    def __init__(self, image, tilesize=None,overlap=None,verbose=False):\n",
    "        \n",
    "        self.im = image\n",
    "        self.s  = np.shape(self.im)[:2]\n",
    "        if tilesize is None:tilesize=self.s[0]//4\n",
    "        self.t  = tilesize\n",
    "        if overlap is None :overlap =tilesize//4\n",
    "        self.o  = overlap\n",
    "        self.verbose=verbose\n",
    "        self.verdata()\n",
    "        self.to = self.t-self.o\n",
    "        self.nbt= [(self.s[0]-self.o)//self.to+1,(self.s[1]-self.o)//self.to+1]\n",
    "        self.p  = None\n",
    "        self.pIm= None\n",
    "        self.tl = None\n",
    "        \n",
    "    def verdata(self):\n",
    "        if (np.shape(self.im)[0]%2)!=0:\n",
    "            if self.verbose:print(\"Changing image to an even dimension value, one pixel was removed on axis zero.\")\n",
    "            self.im=self.im[:-1]\n",
    "        if (np.shape(self.im)[1]%2)!=0:\n",
    "            if self.verbose:print(\"Changing image to an even dimension value, one pixel was removed on axis one.\")\n",
    "            self.im=self.im[:,:-1]\n",
    "        if self.o%2!=0:\n",
    "            if self.verbose:print(\"Please use even value for overlap, overlap was reduced by one.\")\n",
    "            self.o-=1\n",
    "        if self.t>np.shape(self.im)[0] or self.t>np.shape(self.im)[1]:\n",
    "            if self.verbose:print(\"You probably didn't do what you want, you will just have one padded image. (Tile size larger than image)\")\n",
    "                      \n",
    "    def detpad(self):\n",
    "        psize=[(self.nbt[0]*self.to+self.o)-self.s[0],(self.nbt[1]*self.to+self.o)-self.s[1]]\n",
    "        for i in range(len(psize)):\n",
    "            if  psize[i]==self.to:\n",
    "                psize[i]%=self.to\n",
    "                self.nbt[i]-=1\n",
    "        return psize\n",
    "    \n",
    "    def padding(self,mode=\"reflect\"):\n",
    "        if self.p is None:\n",
    "            self.p=self.detpad()\n",
    "        padval=int(self.p[0]/2),int(self.p[1]/2)\n",
    "        pIm=np.pad(self.im,((padval[0],padval[0]),(padval[1],padval[1]),(0,0)),mode=mode)\n",
    "        del padval\n",
    "        gc.collect()\n",
    "        return pIm\n",
    "    \n",
    "    def tilegeneration(self):\n",
    "        if self.pIm is None:\n",
    "            self.pIm=self.padding()\n",
    "        tiles=[]\n",
    "        for i in range (self.nbt[0]):\n",
    "            for j in range (self.nbt[1]):\n",
    "                tiles.append(self.pIm[i*self.to:i*self.to+self.t,j*self.to:j*self.to+self.t])\n",
    "        return tiles\n",
    "    \n",
    "    def tilevis(self,concat=True):\n",
    "        if self.tl is None:\n",
    "            self.tl=self.tilegeneration()\n",
    "        plt.figure(figsize =( 3*self.nbt[1], 3*self.nbt[0]))\n",
    "        if not concat:\n",
    "            for i in range(self.nbt[0]):\n",
    "                for j in range(self.nbt[1]):\n",
    "                    ax = plt.subplot(self.nbt[0], self.nbt[1], i*self.nbt[1]+j+1)\n",
    "                    ax.axis(\"off\")\n",
    "                    plt.imshow(self.tl[i*self.nbt[1]+j])\n",
    "        else:\n",
    "            im=[]\n",
    "            for i in range(self.nbt[0]):\n",
    "                line=[]\n",
    "                for j in range(self.nbt[1]):\n",
    "                    if j==0: line=self.tl[i*self.nbt[1]+j]\n",
    "                    else: line = np.concatenate((line,self.tl[i*self.nbt[1]+j]),axis=1)\n",
    "                if i==0:im=line\n",
    "                else:im=np.concatenate((im,line),axis=0)\n",
    "            plt.imshow(im[...,0])\n",
    "        del im\n",
    "        gc.collect()\n",
    "        plt.show()\n",
    "        \n",
    "    \n",
    "    def detmask(self):\n",
    "        if self.pIm is None:\n",
    "            self.pIm=self.padding()\n",
    "        mask=np.zeros(np.shape(self.pIm)[:2])\n",
    "        for i in range (self.nbt[0]):\n",
    "            for j in range (self.nbt[1]):\n",
    "                mask[i*self.to:i*self.to+self.t,j*self.to:j*self.to+self.t]+=np.ones((self.t,self.t))\n",
    "        return mask[int(self.p[0]/2):self.s[0]+int(self.p[0]/2),int(self.p[1]/2):self.s[1]+int(self.p[1]/2)]\n",
    "    \n",
    "    def reconstruct(self,tl=None):\n",
    "        if tl is None:\n",
    "            tl=self.tilegeneration()\n",
    "        reim=np.zeros(np.shape(self.pIm))\n",
    "        lb=int(self.o/2)\n",
    "        rb=self.t-lb\n",
    "        for i in range (self.nbt[0]):\n",
    "            for j in range (self.nbt[1]):\n",
    "                reim[i*self.to+lb:i*self.to+rb,j*self.to+lb:j*self.to+rb]+=tl[i*self.nbt[1]+j][lb:rb,lb:rb]\n",
    "        reim=reim[int(self.p[0]/2):self.s[0]+int(self.p[0]/2),int(self.p[1]/2):self.s[1]+int(self.p[1]/2)]\n",
    "        if np.max(reim)<=1:\n",
    "            reim=(reim*65536)\n",
    "        return reim.astype(\"uint16\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Image Processing for network training\"\"\"\n",
    "#calling of the tiling procedure and defining a function to apply on a whole tensor\n",
    "def tiling(dataset,tilesize=256,overlap=64):\n",
    "    \n",
    "    tiled=[]\n",
    "    for i in dataset:\n",
    "        tempi=Tile(i,tilesize,overlap)\n",
    "        tiled.append(tempi.tilegeneration())\n",
    "    del tempi\n",
    "    gc.collect()\n",
    "    return np.reshape(tiled,(-1,tilesize,tilesize,np.shape(dataset)[-1]))\n",
    "\n",
    "#applying the tiling\n",
    "x_train,y_train=tiling(x_train),tiling(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"2022-04-21_BioSamples_Acquisition/\"\n",
    "data=[imread(path+im) for im in listdir(path)]\n",
    "data_concat = (np.concatenate((data[0],data[1],data[2],data[3],data[4],data[5],data[6]),axis = 0))\n",
    "X = data_concat[:,2]\n",
    "Y = data_concat[:,1]\n",
    "X=np.expand_dims(X,axis=3)\n",
    "Y=np.expand_dims(Y,axis=3)\n",
    "x_train,y_train=np.concatenate((x_train,tiling(X)),axis=0),np.concatenate((y_train,tiling(Y)),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"2022-07-08_Fibers/\"\n",
    "data=[imread(path+im) for im in listdir(path)]\n",
    "data_concat = np.copy(data)\n",
    "X = data_concat[:,2]\n",
    "Y = data_concat[:,1]\n",
    "X=np.expand_dims(X,axis=3)\n",
    "Y=np.expand_dims(Y,axis=3)\n",
    "x_train,y_train=np.concatenate((x_train,tiling(X)),axis=0),np.concatenate((y_train,tiling(Y)),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_processed=((x_train/32768)-1).astype(\"float32\")\n",
    "y_train_processed=((y_train/32768)-1).astype(\"float32\")\n",
    "dataset = [x_train_processed,y_train_processed]\n",
    "image_shape = dataset[0].shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Network creating (brand new or loaded)\"\"\"\n",
    "new=False\n",
    "if new : #Used to initialize the model with empty settings(weights) for the network\n",
    "    # define the models and putting them together\n",
    "    d_model = define_discriminator(image_shape)\n",
    "    g_model = define_generator(image_shape)\n",
    "    gan_model = define_gan(g_model, d_model, image_shape)\n",
    "if not new : #Used to load a previously trained model\n",
    "    g_model = tf.keras.models.load_model(\"Networks/Pix2Pix_gen__7_low_MSE\") \n",
    "    d_model = tf.keras.models.load_model(\"Networks/Pix2Pix_det__7_low_MSE\") \n",
    "    gan_model = define_gan(g_model, d_model, image_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Network training, save=True => Auto saving on drive\"\"\"\n",
    "train(d_model, g_model, gan_model, dataset, n_epochs=100, n_batch=2048,save=True) #training loop"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
